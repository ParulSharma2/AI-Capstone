{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76eb889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES DataFrame:\n",
      "          drug  chembl_id                                             smiles\n",
      "0  paracetamol  CHEMBL112                                 CC(=O)Nc1ccc(O)cc1\n",
      "1    ibuprofen  CHEMBL521                         CC(C)Cc1ccc(C(C)C(=O)O)cc1\n",
      "2    celecoxib  CHEMBL118  Cc1ccc(-c2cc(C(F)(F)F)nn2-c2ccc(S(N)(=O)=O)cc2...\n"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "import pandas as pd  \n",
    "\n",
    "# Step 1: Define a list of drug names we are interested in\n",
    "drug_names = ['paracetamol', 'ibuprofen', 'celecoxib']\n",
    "\n",
    "# Step 2: Create an empty list to collect drug information\n",
    "drug_data = []\n",
    "\n",
    "# Step 3: Loop through each drug to query ChEMBL and retrieve SMILES\n",
    "for drug in drug_names:\n",
    "    # Use ChEMBL API to search for the drug and get its ChEMBL ID\n",
    "    url = f\"https://www.ebi.ac.uk/chembl/api/data/molecule/search?q={drug}\"\n",
    "    response = requests.get(url, headers={\"Accept\": \"application/json\"})\n",
    "\n",
    "    # If the search is successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        # Get the first hit from the search result\n",
    "        if results['molecules']:\n",
    "            chembl_id = results['molecules'][0]['molecule_chembl_id']\n",
    "\n",
    "            # Use the ChEMBL ID to get molecule details (like SMILES)\n",
    "            mol_url = f\"https://www.ebi.ac.uk/chembl/api/data/molecule/{chembl_id}.json\"\n",
    "            mol_response = requests.get(mol_url)\n",
    "\n",
    "            if mol_response.status_code == 200:\n",
    "                mol_data = mol_response.json()\n",
    "\n",
    "                # Extract canonical SMILES string\n",
    "                smiles = mol_data.get('molecule_structures', {}).get('canonical_smiles', 'NA')\n",
    "\n",
    "                # Append results to the list\n",
    "                drug_data.append({'drug': drug, 'chembl_id': chembl_id, 'smiles': smiles})\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {drug}\")\n",
    "\n",
    "# Step 4: Convert collected data into a pandas DataFrame\n",
    "df_smiles = pd.DataFrame(drug_data)\n",
    "\n",
    "# Step 5: Display the results\n",
    "print(\"SMILES DataFrame:\")\n",
    "print(df_smiles)\n",
    "\n",
    "# Optional: Save to CSV\n",
    "df_smiles.to_csv(\"drug_smiles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "371bcc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COX1 Sequence (first 100 amino acids):\n",
      "MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGICVRFGLDRYQCDCTRTGYSGPNCTIPGLWTWLRNSLRPSPSFTHFLLTHGRWFWE...\n",
      "\n",
      "\n",
      "COX2 Sequence (first 100 amino acids):\n",
      "MLARALLLCAVLALSHTANPCCSHPCQNRGVCMSVGFDQYKCDCTRTGFYGENCSTPEFLTRIKLFLKPTPNTVHYILTHFKGFWNVVNNIPFLRNAIMS...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define UniProt IDs for COX-1 and COX-2\n",
    "protein_ids = {\n",
    "    \"COX1\": \"P23219\",  # PTGS1 - Cyclooxygenase-1\n",
    "    \"COX2\": \"P35354\"   # PTGS2 - Cyclooxygenase-2\n",
    "}\n",
    "\n",
    "# Step 2: Create a dictionary to store protein sequences\n",
    "protein_seqs = {}\n",
    "\n",
    "# Step 3: Fetch sequences using UniProt REST API\n",
    "for name, uniprot_id in protein_ids.items():\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.fasta\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        fasta_data = response.text\n",
    "\n",
    "        # Remove the FASTA header (starting with '>') and join the sequence lines\n",
    "        sequence = ''.join(fasta_data.split('\\n')[1:])\n",
    "        protein_seqs[name] = sequence\n",
    "    else:\n",
    "        print(f\"Error fetching {name} sequence.\")\n",
    "\n",
    "# Step 4: Display a preview of the sequences\n",
    "for name, seq in protein_seqs.items():\n",
    "    print(f\"\\n{name} Sequence (first 100 amino acids):\\n{seq[:100]}...\\n\")\n",
    "\n",
    "# Optional: Save to FASTA files\n",
    "with open(\"COX1.fasta\", \"w\") as f:\n",
    "    f.write(f\">COX1|P23219\\n{protein_seqs['COX1']}\")\n",
    "\n",
    "with open(\"COX2.fasta\", \"w\") as f:\n",
    "    f.write(f\">COX2|P35354\\n{protein_seqs['COX2']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6009f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          drug  chembl_id  FP_0  FP_1  FP_2  FP_3  FP_4  FP_5  FP_6  FP_7  \\\n",
      "0  paracetamol  CHEMBL112     0     0     0     0     0     0     0     0   \n",
      "1    ibuprofen  CHEMBL521     0     1     0     0     0     0     0     0   \n",
      "2    celecoxib  CHEMBL118     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   ...  FP_1014  FP_1015  FP_1016  FP_1017  FP_1018  FP_1019  FP_1020  \\\n",
      "0  ...        0        0        0        1        0        0        0   \n",
      "1  ...        0        0        0        0        0        0        0   \n",
      "2  ...        0        0        0        0        0        0        0   \n",
      "\n",
      "   FP_1021  FP_1022  FP_1023  \n",
      "0        0        0        0  \n",
      "1        0        0        0  \n",
      "2        0        0        0  \n",
      "\n",
      "[3 rows x 1026 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:49:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[16:49:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[16:49:06] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import pandas as pd\n",
    "\n",
    "# Example: Load SMILES data from the previous step\n",
    "df_smiles = pd.read_csv(\"drug_smiles.csv\")\n",
    "\n",
    "# Function to generate Morgan fingerprint\n",
    "def generate_morgan_fp(smiles, radius=2, nBits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits)\n",
    "        return list(fp)\n",
    "    else:\n",
    "        return [0] * nBits  # Return zero vector if SMILES is invalid\n",
    "\n",
    "# Apply the function to all SMILES\n",
    "df_smiles[\"fingerprint\"] = df_smiles[\"smiles\"].apply(generate_morgan_fp)\n",
    "\n",
    "# Expand fingerprint list into separate columns\n",
    "fingerprint_df = pd.DataFrame(df_smiles[\"fingerprint\"].tolist(), index=df_smiles.index)\n",
    "fingerprint_df.columns = [f\"FP_{i}\" for i in range(fingerprint_df.shape[1])]\n",
    "\n",
    "# Combine with drug name\n",
    "ligand_features = pd.concat([df_smiles[[\"drug\", \"chembl_id\"]], fingerprint_df], axis=1)\n",
    "\n",
    "# Preview\n",
    "print(ligand_features.head())\n",
    "\n",
    "# Save for later steps\n",
    "ligand_features.to_csv(\"ligand_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "524f8a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  protein         A         C         D         E         F         G  \\\n",
      "0    COX1  0.041736  0.021703  0.040067  0.060100  0.065109  0.075125   \n",
      "1    COX2  0.051325  0.021523  0.043046  0.059603  0.062914  0.061258   \n",
      "\n",
      "          H         I         K  ...         M         N         P         Q  \\\n",
      "0  0.030050  0.041736  0.041736  ...  0.030050  0.031720  0.076795  0.045075   \n",
      "1  0.031457  0.056291  0.056291  ...  0.024834  0.048013  0.066225  0.051325   \n",
      "\n",
      "          R         S         T         V         W         Y  \n",
      "0  0.055092  0.055092  0.050083  0.053422  0.016694  0.045075  \n",
      "1  0.044702  0.057947  0.056291  0.057947  0.009934  0.044702  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the function (taught in class)\n",
    "def aa_composition(seq):\n",
    "    freq = {}\n",
    "    for aa in 'ACDEFGHIKLMNPQRSTVWY':\n",
    "        freq[aa] = seq.count(aa) / len(seq)\n",
    "    return pd.Series(freq)\n",
    "\n",
    "# Example input (from Step 1B)\n",
    "protein_seqs = {\n",
    "    \"COX1\": open(\"COX1.fasta\").read().split(\"\\n\", 1)[1].replace(\"\\n\", \"\"),\n",
    "    \"COX2\": open(\"COX2.fasta\").read().split(\"\\n\", 1)[1].replace(\"\\n\", \"\")\n",
    "}\n",
    "\n",
    "# Apply the function\n",
    "protein_features = pd.DataFrame({\n",
    "    name: aa_composition(seq) for name, seq in protein_seqs.items()\n",
    "}).T.reset_index().rename(columns={\"index\": \"protein\"})\n",
    "\n",
    "# Preview\n",
    "print(protein_features)\n",
    "\n",
    "# Save for next stage\n",
    "protein_features.to_csv(\"protein_features.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1065687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          drug  chembl_id protein  lig_FP_0  lig_FP_1  lig_FP_2  lig_FP_3  \\\n",
      "0  paracetamol  CHEMBL112    COX1         0         0         0         0   \n",
      "1  paracetamol  CHEMBL112    COX2         0         0         0         0   \n",
      "2    ibuprofen  CHEMBL521    COX1         0         1         0         0   \n",
      "3    ibuprofen  CHEMBL521    COX2         0         1         0         0   \n",
      "4    celecoxib  CHEMBL118    COX1         0         0         0         0   \n",
      "\n",
      "   lig_FP_4  lig_FP_5  lig_FP_6  ...    prot_M    prot_N    prot_P    prot_Q  \\\n",
      "0         0         0         0  ...  0.030050  0.031720  0.076795  0.045075   \n",
      "1         0         0         0  ...  0.024834  0.048013  0.066225  0.051325   \n",
      "2         0         0         0  ...  0.030050  0.031720  0.076795  0.045075   \n",
      "3         0         0         0  ...  0.024834  0.048013  0.066225  0.051325   \n",
      "4         0         0         0  ...  0.030050  0.031720  0.076795  0.045075   \n",
      "\n",
      "     prot_R    prot_S    prot_T    prot_V    prot_W    prot_Y  \n",
      "0  0.055092  0.055092  0.050083  0.053422  0.016694  0.045075  \n",
      "1  0.044702  0.057947  0.056291  0.057947  0.009934  0.044702  \n",
      "2  0.055092  0.055092  0.050083  0.053422  0.016694  0.045075  \n",
      "3  0.044702  0.057947  0.056291  0.057947  0.009934  0.044702  \n",
      "4  0.055092  0.055092  0.050083  0.053422  0.016694  0.045075  \n",
      "\n",
      "[5 rows x 1047 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Step 1: Load ligand and protein features\n",
    "ligands = pd.read_csv(\"ligand_features.csv\")\n",
    "proteins = pd.read_csv(\"protein_features.csv\")\n",
    "\n",
    "# Step 2: Create all combinations of ligand-protein pairs\n",
    "pairs = list(itertools.product(ligands.index, proteins.index))\n",
    "\n",
    "# Step 3: Initialize an empty list to hold merged feature vectors\n",
    "merged_data = []\n",
    "\n",
    "for ligand_idx, protein_idx in pairs:\n",
    "    ligand_row = ligands.iloc[ligand_idx]\n",
    "    protein_row = proteins.iloc[protein_idx]\n",
    "\n",
    "    # Combine info into one row\n",
    "    combined_row = {\n",
    "        'drug': ligand_row['drug'],\n",
    "        'chembl_id': ligand_row['chembl_id'],\n",
    "        'protein': protein_row['protein']\n",
    "    }\n",
    "\n",
    "    # Add all fingerprint columns\n",
    "    for col in ligand_row.index:\n",
    "        if col.startswith(\"FP_\"):\n",
    "            combined_row[f\"lig_{col}\"] = ligand_row[col]\n",
    "\n",
    "    # Add all protein feature columns\n",
    "    for aa in 'ACDEFGHIKLMNPQRSTVWY':\n",
    "        combined_row[f\"prot_{aa}\"] = protein_row[aa]\n",
    "\n",
    "    merged_data.append(combined_row)\n",
    "\n",
    "# Step 4: Convert to DataFrame\n",
    "final_df = pd.DataFrame(merged_data)\n",
    "\n",
    "# Step 5: Preview and Save\n",
    "print(final_df.head())\n",
    "final_df.to_csv(\"drug_protein_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b795bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          drug protein  label\n",
      "0  paracetamol    COX1      1\n",
      "1  paracetamol    COX2      0\n",
      "2    ibuprofen    COX1      1\n",
      "3    ibuprofen    COX2      1\n",
      "4    celecoxib    COX1      0\n",
      "5    celecoxib    COX2      1\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load your feature dataset\n",
    "df = pd.read_csv(\"drug_protein_features.csv\")\n",
    "\n",
    "# Step 2: Define known positive interactions (from literature)\n",
    "positive_pairs = [\n",
    "    (\"paracetamol\", \"COX1\"),\n",
    "    (\"ibuprofen\", \"COX1\"),\n",
    "    (\"ibuprofen\", \"COX2\"),\n",
    "    (\"celecoxib\", \"COX2\")\n",
    "]\n",
    "\n",
    "# Step 3: Assign labels\n",
    "df[\"label\"] = df.apply(lambda row: 1 if (row[\"drug\"], row[\"protein\"]) in positive_pairs else 0, axis=1)\n",
    "\n",
    "# Step 4: Preview and save\n",
    "print(df[[\"drug\", \"protein\", \"label\"]])\n",
    "df.to_csv(\"final_dataset_labeled.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e6468",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "859b1aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "ROC-AUC Score: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandragarcia/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/sandragarcia/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/sandragarcia/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Step 1: Load the labeled feature dataset\n",
    "df = pd.read_csv(\"final_dataset_labeled.csv\")\n",
    "\n",
    "# Step 2: Prepare feature matrix (X) and label vector (y)\n",
    "# Drop non-numeric columns ('drug', 'protein', 'chembl_id', and 'label') for model input\n",
    "X = df.drop(columns=[\"drug\", \"protein\", \"chembl_id\", \"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Step 3: Split the dataset into train and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Initialize and train a Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]  # for ROC-AUC\n",
    "\n",
    "# Step 6: Evaluate model performance\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e6cf8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "ROC-AUC Score: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandragarcia/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/sandragarcia/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/sandragarcia/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Step 1: Load the labeled feature dataset\n",
    "df = pd.read_csv(\"final_dataset_labeled.csv\")\n",
    "\n",
    "# Step 2: Prepare feature matrix (X) and label vector (y)\n",
    "X = df.drop(columns=[\"drug\", \"protein\", \"chembl_id\", \"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Step 3: Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Initialize and train the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 6: Evaluate model\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d82cb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGUST 8TH 2 CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d414a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COX1: Retrieved 653 raw activities.\n",
      "COX2: Retrieved 192 raw activities.\n",
      "Final balanced dataset: 374 rows (187 per class)\n"
     ]
    }
   ],
   "source": [
    "#GOOD CODE\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define ChEMBL Target IDs for COX1 and COX2\n",
    "targets = {\n",
    "    \"COX1\": \"CHEMBL2095188\",\n",
    "    \"COX2\": \"CHEMBL2094253\"\n",
    "}\n",
    "\n",
    "# Parameters to fetch only IC50 values\n",
    "base_params = {\n",
    "    \"standard_type\": \"IC50\",\n",
    "    \"limit\": 1000\n",
    "}\n",
    "\n",
    "# Function to fetch activity data from ChEMBL\n",
    "def fetch_activity_data(target_name, chembl_id):\n",
    "    all_data = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        params = base_params.copy()\n",
    "        params.update({\n",
    "            \"target_chembl_id\": chembl_id,\n",
    "            \"offset\": offset\n",
    "        })\n",
    "\n",
    "        url = \"https://www.ebi.ac.uk/chembl/api/data/activity.json\"\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error retrieving {target_name} data.\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        activities = data.get(\"activities\", [])\n",
    "        if not activities:\n",
    "            break\n",
    "\n",
    "        all_data.extend(activities)\n",
    "        offset += 1000\n",
    "\n",
    "    print(f\"{target_name}: Retrieved {len(all_data)} raw activities.\")\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Step 1: Download activity data for COX1 and COX2\n",
    "df_cox1 = fetch_activity_data(\"COX1\", targets[\"COX1\"])\n",
    "df_cox2 = fetch_activity_data(\"COX2\", targets[\"COX2\"])\n",
    "\n",
    "# Step 2: Clean/filter IC50 values in nanomolar (nM)\n",
    "def clean_and_filter(df):\n",
    "    df = df[df[\"standard_value\"].notna()]               # Remove missing IC50s\n",
    "    df = df[df[\"standard_units\"] == \"nM\"]                # Only nanomolar units\n",
    "    df = df[df[\"standard_type\"] == \"IC50\"]               # Only IC50 values\n",
    "    df = df[df[\"canonical_smiles\"].notna()]              # Make sure SMILES exist\n",
    "    return df[[\"canonical_smiles\", \"standard_value\"]]    # Keep only needed columns\n",
    "\n",
    "df_cox1_clean = clean_and_filter(df_cox1)\n",
    "df_cox2_clean = clean_and_filter(df_cox2)\n",
    "\n",
    "# Step 3: Balance the two datasets (same number of ligands)\n",
    "min_len = min(len(df_cox1_clean), len(df_cox2_clean))\n",
    "df_cox1_bal = df_cox1_clean.sample(n=min_len, random_state=42)\n",
    "df_cox2_bal = df_cox2_clean.sample(n=min_len, random_state=42)\n",
    "\n",
    "# Step 4: Add binary labels (0 = COX1, 1 = COX2)\n",
    "df_cox1_bal[\"label\"] = 0\n",
    "df_cox2_bal[\"label\"] = 1\n",
    "\n",
    "# Step 5: Merge and shuffle the dataset\n",
    "df_combined = pd.concat([df_cox1_bal, df_cox2_bal], ignore_index=True)\n",
    "df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Step 6: Save to CSV\n",
    "df_combined.to_csv(\"balanced_cox1_2_ic50.csv\", index=False)\n",
    "print(f\"Final balanced dataset: {len(df_combined)} rows ({min_len} per class)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee27d82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COX1: Retrieved 653 raw activities.\n",
      "COX2: Retrieved 192 raw activities.\n",
      "Saved 'cox1_clean_ic50.csv' and 'cox2_clean_ic50.csv'\n",
      "Final dataset saved as 'merged_balanced_cox1_2_ic50.csv'\n",
      "Dataset contains 374 rows → 187 for each class.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Target ChEMBL IDs\n",
    "targets = {\n",
    "    \"COX1\": \"CHEMBL2095188\",\n",
    "    \"COX2\": \"CHEMBL2094253\"\n",
    "}\n",
    "\n",
    "# Base API parameters\n",
    "base_params = {\n",
    "    \"standard_type\": \"IC50\",\n",
    "    \"limit\": 1000  # fetch max per call\n",
    "}\n",
    "\n",
    "# Function to download activities\n",
    "def fetch_activity_data(target_name, chembl_id):\n",
    "    all_data = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        params = base_params.copy()\n",
    "        params.update({\n",
    "            \"target_chembl_id\": chembl_id,\n",
    "            \"offset\": offset\n",
    "        })\n",
    "\n",
    "        url = \"https://www.ebi.ac.uk/chembl/api/data/activity.json\"\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error retrieving {target_name} data.\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        activities = data.get(\"activities\", [])\n",
    "        if not activities:\n",
    "            break\n",
    "\n",
    "        all_data.extend(activities)\n",
    "        offset += 1000\n",
    "\n",
    "    print(f\"{target_name}: Retrieved {len(all_data)} raw activities.\")\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Step 1: Fetch activities\n",
    "df_cox1 = fetch_activity_data(\"COX1\", targets[\"COX1\"])\n",
    "df_cox2 = fetch_activity_data(\"COX2\", targets[\"COX2\"])\n",
    "\n",
    "# Step 2: Filter the data\n",
    "def clean_and_filter(df):\n",
    "    df = df[df[\"standard_value\"].notna()]\n",
    "    df = df[df[\"standard_units\"] == \"nM\"]\n",
    "    df = df[df[\"standard_type\"] == \"IC50\"]\n",
    "    df = df[df[\"canonical_smiles\"].notna()]  # Keep only rows with SMILES\n",
    "    return df\n",
    "\n",
    "df_cox1_clean = clean_and_filter(df_cox1)\n",
    "df_cox2_clean = clean_and_filter(df_cox2)\n",
    "\n",
    "# Step 3: Save cleaned data separately\n",
    "df_cox1_clean.to_csv(\"cox1_clean_ic50.csv\", index=False)\n",
    "df_cox2_clean.to_csv(\"cox2_clean_ic50.csv\", index=False)\n",
    "print(f\"Saved 'cox1_clean_ic50.csv' and 'cox2_clean_ic50.csv'\")\n",
    "\n",
    "# Step 4: Balance datasets by sampling\n",
    "min_len = min(len(df_cox1_clean), len(df_cox2_clean))\n",
    "df_cox1_bal = df_cox1_clean.sample(n=min_len, random_state=42).copy()\n",
    "df_cox2_bal = df_cox2_clean.sample(n=min_len, random_state=42).copy()\n",
    "\n",
    "# Step 5: Add binary labels\n",
    "df_cox1_bal[\"label\"] = 0\n",
    "df_cox2_bal[\"label\"] = 1\n",
    "\n",
    "# Step 6: Merge into one labeled dataset\n",
    "df_combined = pd.concat([df_cox1_bal, df_cox2_bal], ignore_index=True)\n",
    "df_combined.to_csv(\"merged_balanced_cox1_2_ic50.csv\", index=False)\n",
    "print(f\"Final dataset saved as 'merged_balanced_cox1_2_ic50.csv'\")\n",
    "print(f\"Dataset contains {len(df_combined)} rows → {min_len} for each class.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708df65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:01:58] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morgan fingerprints saved to 'ligand_features_morgan.csv'\n",
      "Amino acid composition saved to 'protein_features_aac.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Load merged dataset\n",
    "df = pd.read_csv(\"merged_balanced_cox1_2_ic50.csv\")\n",
    "\n",
    "# Function to generate Morgan fingerprints\n",
    "def smiles_to_morgan(smiles, radius=2, nBits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [0] * nBits\n",
    "    return list(AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits))\n",
    "\n",
    "# Apply function to all SMILES\n",
    "fingerprints = df[\"canonical_smiles\"].apply(smiles_to_morgan)\n",
    "fp_df = pd.DataFrame(fingerprints.tolist())\n",
    "\n",
    "# Add labels and original SMILES for reference\n",
    "fp_df[\"label\"] = df[\"label\"]\n",
    "fp_df[\"canonical_smiles\"] = df[\"canonical_smiles\"]\n",
    "\n",
    "# Save to CSV\n",
    "fp_df.to_csv(\"ligand_features_morgan.csv\", index=False)\n",
    "print(\"Morgan fingerprints saved to 'ligand_features_morgan.csv'\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load FASTA sequences (manually pasted or read from file)\n",
    "protein_seqs = {\n",
    "    \"COX1\": \"MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGICVRFGLDRYQCDCTRTGYSGPNCTIPGLWTWLRNSLRPSPSFTHFLLTHGRWFWEFVNATFGLVPGQETLQHTSYNFTNGLYHFKGVDAQEQLSRVLAIVHPGAYEIATTHRLLREHVVRSDELLKPAVQ...\"[:300],\n",
    "    \"COX2\": \"MLARALLLCAVLALSHTANPCCSHPCQNRGVCMSVGFDQYKCDCTRTGFYRPNCTIPELYHYWPQKRQFQISAKVGDVIPVYEMELVPLAENRQEAMEKICLNPATVETTTKTVETTVEDTEETTSTVHFKNKTVVPTVPIAVQDTPEL...\"[:300]\n",
    "}\n",
    "\n",
    "# Function to compute amino acid composition\n",
    "def aa_composition(seq):\n",
    "    aa_list = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    freq = {aa: seq.count(aa)/len(seq) for aa in aa_list}\n",
    "    return pd.Series(freq)\n",
    "\n",
    "# Apply function\n",
    "df_protein_features = pd.DataFrame({name: aa_composition(seq) for name, seq in protein_seqs.items()}).T\n",
    "df_protein_features.to_csv(\"protein_features_aac.csv\")\n",
    "print(\"Amino acid composition saved to 'protein_features_aac.csv'\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11fffe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'protein'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/zw/dm091lnx7jx05gc6myjkzq8w0000gn/T/ipykernel_7218/1736535644.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m label_to_protein = {\u001b[32m0\u001b[39m: \u001b[33m\"COX1\"\u001b[39m, \u001b[32m1\u001b[39m: \u001b[33m\"COX2\"\u001b[39m}\n\u001b[32m      9\u001b[39m ligand_df[\u001b[33m\"protein\"\u001b[39m] = ligand_df[\u001b[33m\"label\"\u001b[39m].map(label_to_protein)\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Step 3: Merge ligand data with the matching protein features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m final_df = ligand_df.merge(protein_df, on=\u001b[33m\"protein\"\u001b[39m, how=\u001b[33m\"left\"\u001b[39m)\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Step 4: Save final machine learning–ready dataset\u001b[39;00m\n\u001b[32m     15\u001b[39m final_df.to_csv(\u001b[33m\"final_dataset_labeled.csv\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m~/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10835\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10836\u001b[39m     ) -> DataFrame:\n\u001b[32m  10837\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10838\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10839\u001b[39m         return merge(\n\u001b[32m  10840\u001b[39m             self,\n\u001b[32m  10841\u001b[39m             right,\n\u001b[32m  10842\u001b[39m             how=how,\n",
      "\u001b[32m~/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32m~/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32m~/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1296\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1297\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1299\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1300\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1301\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32m~/Documents/HUMBER/Clinical Bioinformatics/2nd Semester/Capstone Project/AI-Capstone/.venv/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'protein'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load ligand and protein feature CSVs\n",
    "ligand_df = pd.read_csv(\"ligand_features_morgan.csv\")\n",
    "protein_df = pd.read_csv(\"protein_features_aac.csv\")\n",
    "\n",
    "# Step 2: Map labels to protein names (0 → COX1, 1 → COX2)\n",
    "label_to_protein = {0: \"COX1\", 1: \"COX2\"}\n",
    "ligand_df[\"protein\"] = ligand_df[\"label\"].map(label_to_protein)\n",
    "\n",
    "# Step 3: Merge ligand data with the matching protein features\n",
    "final_df = ligand_df.merge(protein_df, on=\"protein\", how=\"left\")\n",
    "\n",
    "# Step 4: Save final machine learning–ready dataset\n",
    "final_df.to_csv(\"final_dataset_labeled.csv\", index=False)\n",
    "\n",
    "# Step 5: Print summary\n",
    "print(\"Final dataset saved as 'final_dataset_labeled.csv'\")\n",
    "print(f\"Rows: {len(final_df)} — Columns: {final_df.shape[1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
